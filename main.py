import os
import logging
import traceback
from pathlib import Path
from dotenv import load_dotenv
import gradio as gr
import pandas as pd
import numpy as np
import pickle

from config.config import (
    RAW_DATA_DIR, PROCESSED_DATA_DIR, MODELS_DIR,
    DEFAULT_TRACKS_PER_QUERY, MAX_TRACKS_PER_QUERY, 
    MIN_TRACKS_PER_QUERY, TRACKS_QUERY_STEP,
    LARGE_DATASET_DEFAULT_SIZE, LARGE_DATASET_BATCH_SIZE, LARGE_DATASET_SAVE_INTERVAL
)
from utils.data_fetcher import fetch_initial_dataset
from utils.data_processor import DataProcessor
from models.hybrid_model import MetadataRecommender
from models.weighted_content_model import WeightedContentRecommender

# Thiáº¿t láº­p logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Load biáº¿n mÃ´i trÆ°á»ng
load_dotenv(dotenv_path=Path(__file__).parent / '.env')

# Biáº¿n toÃ n cá»¥c cho model
model = None
weighted_model = None

def initialize_model():
    """Khá»Ÿi táº¡o model khi khá»Ÿi Ä‘á»™ng á»©ng dá»¥ng"""
    global model, weighted_model
    model_path = os.path.join(MODELS_DIR, 'metadata_recommender.pkl')
    weighted_model_path = os.path.join(MODELS_DIR, 'weighted_content_recommender.pkl')

    # MetadataRecommender
    if os.path.exists(model_path):
        try:
            model = MetadataRecommender.load(model_path)
            logging.info(f"ÄÃ£ náº¡p model tá»« {model_path}")
            logging.info(f"Model Ä‘Æ°á»£c huáº¥n luyá»‡n vÃ o: {model.train_time}")
        except Exception as e:
            logging.error(f"Lá»—i khi náº¡p model: {e}")
            model = None

    # WeightedContentRecommender
    if os.path.exists(weighted_model_path):
        try:
            weighted_model = WeightedContentRecommender.load(weighted_model_path)
            logging.info(f"ÄÃ£ náº¡p weighted model tá»« {weighted_model_path}")
        except Exception as e:
            logging.error(f"Lá»—i khi náº¡p weighted model: {e}")
            weighted_model = None

def check_spotify_credentials():
    from config.config import SPOTIFY_CLIENT_ID, SPOTIFY_CLIENT_SECRET
    return bool(SPOTIFY_CLIENT_ID and SPOTIFY_CLIENT_SECRET)

def setup_initial_dataset(progress=gr.Progress(), tracks_per_query=DEFAULT_TRACKS_PER_QUERY):
    """Thiáº¿t láº­p bá»™ dá»¯ liá»‡u ban Ä‘áº§u vá»›i progress bar"""
    if not check_spotify_credentials():
        return "âš ï¸ Thiáº¿u thÃ´ng tin xÃ¡c thá»±c Spotify. Vui lÃ²ng thiáº¿t láº­p file .env."
    os.makedirs(RAW_DATA_DIR, exist_ok=True)
    progress(0.1, desc="Äang thu tháº­p dá»¯ liá»‡u tá»« Spotify...")
    try:
        tracks_df = fetch_initial_dataset(tracks_per_query=tracks_per_query)
        if tracks_df is None or tracks_df.empty:
            return "âŒ KhÃ´ng thá»ƒ láº¥y dá»¯ liá»‡u bÃ i hÃ¡t tá»« Spotify."
        progress(0.6, desc="Äang xá»­ lÃ½ dá»¯ liá»‡u...")
        processor = DataProcessor()
        processor.process_all()
        progress(1.0, desc="HoÃ n táº¥t!")
        return f"âœ… ÄÃ£ thiáº¿t láº­p dá»¯ liá»‡u vá»›i {len(tracks_df)} bÃ i hÃ¡t."
    except Exception as e:
        logger.error(f"Lá»—i thiáº¿t láº­p dá»¯ liá»‡u: {e}\n{traceback.format_exc()}")
        return f"âŒ Lá»—i thiáº¿t láº­p dá»¯ liá»‡u: {e}"

def train_model():
    """Huáº¥n luyá»‡n hoáº·c náº¡p láº¡i mÃ´ hÃ¬nh Ä‘á» xuáº¥t dá»±a trÃªn metadata"""
    global model, weighted_model
    try:
        # ÄÆ°á»ng dáº«n Ä‘á»ƒ lÆ°u/náº¡p mÃ´ hÃ¬nh
        model_path = os.path.join(MODELS_DIR, 'metadata_recommender.pkl')
        weighted_model_path = os.path.join(MODELS_DIR, 'weighted_content_recommender.pkl')

        # Kiá»ƒm tra xem mÃ´ hÃ¬nh Ä‘Ã£ tá»“n táº¡i chÆ°a
        if os.path.exists(model_path):
            logging.info("TÃ¬m tháº¥y mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n, Ä‘ang náº¡p...")
            model = MetadataRecommender.load(model_path)
            logging.info(f"ÄÃ£ náº¡p mÃ´ hÃ¬nh thÃ nh cÃ´ng (Ä‘Æ°á»£c huáº¥n luyá»‡n vÃ o: {model.train_time})")
        else:
            logging.info("KhÃ´ng tÃ¬m tháº¥y mÃ´ hÃ¬nh Ä‘Ã£ lÆ°u, Ä‘ang huáº¥n luyá»‡n má»›i...")
            processed_path = os.path.join(PROCESSED_DATA_DIR, 'track_features.csv')
            if not os.path.exists(processed_path):
                processor = DataProcessor()
                processor.process_all()
            tracks_df = pd.read_csv(processed_path)
            model = MetadataRecommender()
            model.train(tracks_df)
            model.save(model_path)
            logging.info(f"ÄÃ£ huáº¥n luyá»‡n vÃ  lÆ°u mÃ´ hÃ¬nh MetadataRecommender thÃ nh cÃ´ng!")

        # WeightedContentRecommender
        if os.path.exists(weighted_model_path):
            logging.info("TÃ¬m tháº¥y weighted model Ä‘Ã£ huáº¥n luyá»‡n, Ä‘ang náº¡p...")
            weighted_model = WeightedContentRecommender.load(weighted_model_path)
            logging.info("ÄÃ£ náº¡p weighted model thÃ nh cÃ´ng!")
        else:
            logging.info("KhÃ´ng tÃ¬m tháº¥y weighted model Ä‘Ã£ lÆ°u, Ä‘ang huáº¥n luyá»‡n má»›i...")
            processed_path = os.path.join(PROCESSED_DATA_DIR, 'track_features.csv')
            if not os.path.exists(processed_path):
                processor = DataProcessor()
                processor.process_all()
            tracks_df = pd.read_csv(processed_path)
            weighted_model = WeightedContentRecommender()
            weighted_model.train(tracks_df)
            weighted_model.save(weighted_model_path)
            logging.info("ÄÃ£ huáº¥n luyá»‡n vÃ  lÆ°u weighted model thÃ nh cÃ´ng!")

        return "ÄÃ£ huáº¥n luyá»‡n cáº£ hai mÃ´ hÃ¬nh thÃ nh cÃ´ng!"
    except Exception as e:
        logging.error(f"Lá»—i khi huáº¥n luyá»‡n mÃ´ hÃ¬nh: {str(e)}")
        return f"Lá»—i khi huáº¥n luyá»‡n mÃ´ hÃ¬nh: {str(e)}"

def recommend_similar(song_name, artist_name="", n=10):
    """Enhanced recommendation with better debugging"""
    global model, weighted_model
    if model is None or not model.is_trained:
        return "âš ï¸ MÃ´ hÃ¬nh Metadata chÆ°a Ä‘Æ°á»£c huáº¥n luyá»‡n. Vui lÃ²ng huáº¥n luyá»‡n mÃ´ hÃ¬nh trÆ°á»›c."
    if weighted_model is None or not weighted_model.is_trained:
        return "âš ï¸ MÃ´ hÃ¬nh Weighted chÆ°a Ä‘Æ°á»£c huáº¥n luyá»‡n. Vui lÃ²ng huáº¥n luyá»‡n mÃ´ hÃ¬nh trÆ°á»›c."
    
    try:
        # Load processed data Ä‘á»ƒ kiá»ƒm tra
        processed_path = os.path.join(PROCESSED_DATA_DIR, 'track_features.csv')
        if os.path.exists(processed_path):
            tracks_df = pd.read_csv(processed_path)
            
            # Debug: Log available features
            logger.info(f"Available features: {tracks_df.columns.tolist()}")
            logger.info(f"Dataset shape: {tracks_df.shape}")
            
            # TÃ¬m bÃ i hÃ¡t gá»‘c
            mask = tracks_df['name'].str.lower().str.strip() == song_name.lower().strip()
            if artist_name:
                mask = mask & (tracks_df['artist'].str.lower().str.strip() == artist_name.lower().strip())
            
            found_tracks = tracks_df[mask]
            
            if found_tracks.empty:
                # Enhanced fallback vá»›i suggestions
                available_tracks_sample = tracks_df[['name', 'artist']].head(10)
                
                # TÃ¬m tracks tÆ°Æ¡ng tá»± báº±ng fuzzy matching
                from difflib import get_close_matches
                track_names = tracks_df['name'].tolist()
                close_matches = get_close_matches(song_name, track_names, n=5, cutoff=0.6)
                
                suggestion_text = ""
                if close_matches:
                    suggestion_text = f"\n**Gá»£i Ã½ tÆ°Æ¡ng tá»±:** {', '.join(close_matches[:3])}"
                
                return f"""âŒ KhÃ´ng tÃ¬m tháº¥y bÃ i hÃ¡t **{song_name}** (nghá»‡ sÄ©: {artist_name}) trong dá»¯ liá»‡u.
{suggestion_text}

**Má»™t sá»‘ bÃ i hÃ¡t cÃ³ sáºµn:**
{available_tracks_sample.to_markdown(index=False)}

Vui lÃ²ng kiá»ƒm tra láº¡i tÃªn bÃ i hÃ¡t vÃ  nghá»‡ sÄ©!"""
            
            # Hiá»ƒn thá»‹ thÃ´ng tin bÃ i hÃ¡t gá»‘c vá»›i nhiá»u thÃ´ng tin hÆ¡n
            original_info = found_tracks.iloc[0]
            seed_info = f"""**ðŸŽµ BÃ i hÃ¡t gá»‘c:** {original_info['name']} - {original_info['artist']}
**Popularity:** {original_info.get('popularity', 'N/A')} | **NÄƒm phÃ¡t hÃ nh:** {original_info.get('release_year', 'N/A')}
**Duration:** {original_info.get('duration_min', 0):.1f} phÃºt | **Album:** {original_info.get('album', 'N/A')}

---
"""
        else:
            seed_info = "**Dá»¯ liá»‡u bÃ i hÃ¡t gá»‘c khÃ´ng cÃ³ sáºµn**\n\n---\n"
        
        # Thá»±c hiá»‡n Ä‘á» xuáº¥t vá»›i error handling tá»‘t hÆ¡n
        logger.info(f"Generating recommendations for '{song_name}' by {artist_name}")
        
        try:
            rec1 = model.recommend(track_name=song_name, artist=artist_name, n_recommendations=n)
            model_1_success = True
        except Exception as e:
            logger.error(f"Model 1 failed: {e}")
            rec1 = pd.DataFrame()
            model_1_success = False
        
        try:
            rec2 = weighted_model.recommend(track_name=song_name, artist=artist_name, n_recommendations=n)
            model_2_success = True
        except Exception as e:
            logger.error(f"Model 2 failed: {e}")
            rec2 = pd.DataFrame()
            model_2_success = False
        
        # Táº¡o káº¿t quáº£ vá»›i debug info
        result = seed_info
        
        # Model 1 results
        result += "### ðŸ“Š MetadataRecommender (Content-Based):\n"
        if model_1_success and not rec1.empty:
            display_cols = ['name', 'artist', 'content_score', 'popularity', 'release_year']
            available_cols = [col for col in display_cols if col in rec1.columns]
            result += rec1[available_cols].round(3).to_markdown(index=False) + "\n"
            
            # Add quality metrics
            avg_score = rec1['content_score'].mean() if 'content_score' in rec1.columns else 0
            result += f"\n*Avg similarity: {avg_score:.3f}*\n"
        else:
            result += "âŒ Model failed to generate recommendations\n"
        
        result += "\n---\n"
        
        # Model 2 results
        result += "### âš–ï¸ WeightedContentRecommender (Advanced Scoring):\n"
        if model_2_success and not rec2.empty:
            display_cols = ['name', 'artist', 'final_score', 'popularity', 'release_year']
            available_cols = [col for col in display_cols if col in rec2.columns]
            result += rec2[available_cols].round(3).to_markdown(index=False)
            
            # Add quality metrics
            avg_score = rec2['final_score'].mean() if 'final_score' in rec2.columns else 0
            result += f"\n\n*Avg weighted score: {avg_score:.3f}*"
        else:
            result += "âŒ Model failed to generate recommendations"
        
        return result
        
    except Exception as e:
        logger.error(f"Lá»—i khi Ä‘á» xuáº¥t: {e}\n{traceback.format_exc()}")
        return f"âŒ Lá»—i há»‡ thá»‘ng khi Ä‘á» xuáº¥t: {str(e)}"

def discover_by_genre(genre, n=10):
    global model
    if model is None or not model.is_trained:
        return "âš ï¸ Vui lÃ²ng huáº¥n luyá»‡n mÃ´ hÃ¬nh trÆ°á»›c."
    try:
        recs = model.discover_by_genre(genre, n)
        if recs is None or recs.empty:
            return f"KhÃ´ng tÃ¬m tháº¥y bÃ i hÃ¡t thuá»™c thá»ƒ loáº¡i {genre}."
        result = f"## Top {n} bÃ i hÃ¡t thá»ƒ loáº¡i {genre}\n"
        for i, row in enumerate(recs.itertuples(), 1):
            result += f"{i}. **{row.name}** - {row.artist}\n"
        return result
    except Exception as e:
        logger.error(f"Lá»—i khÃ¡m phÃ¡ thá»ƒ loáº¡i: {e}\n{traceback.format_exc()}")
        return f"âŒ Lá»—i khÃ¡m phÃ¡ thá»ƒ loáº¡i: {e}"

def check_data_status():
    """Check data completeness and quality for recommendation system"""
    try:
        from utils.data_checker import check_data_completeness
        result = check_data_completeness()
        
        # Format result for Gradio display
        score = result['readiness_score']
        max_score = result['max_score']
        tracks_count = result['tracks_count']
        
        # Use text-based status indicators
        if score >= 6:
            status_emoji = "[EXCELLENT]"
            status_text = "Production Ready!"
        elif score >= 4:
            status_emoji = "[GOOD]"
            status_text = "Ready with minor improvements"
        elif score >= 2:
            status_emoji = "[FAIR]"
            status_text = "Basic functionality available"
        else:
            status_emoji = "[POOR]"
            status_text = "More data needed"
        
        summary = f"""
## {status_emoji} Data Status Report

**Overall Readiness:** {score}/{max_score} ({score/max_score*100:.1f}%)

**Dataset Size:** {tracks_count:,} tracks

**Status:** {status_text}

**Detailed analysis logged to console.**

**Next Steps:**
- Check console output for detailed breakdown
- If score < 6, consider collecting more data
- Run data processing if files are missing
        """
        
        return summary
        
    except Exception as e:
        logger.error(f"Error checking data status: {e}")
        return f"[ERROR] Error checking data status: {str(e)}"

def create_ui():
    with gr.Blocks(title="Music Recommender (Real Spotify Metadata)", theme=gr.themes.Soft()) as app:
        gr.Markdown("# ðŸŽµ Music Recommender - Real Spotify Data Only")
        gr.Markdown("*Há»‡ thá»‘ng Ä‘á» xuáº¥t Ã¢m nháº¡c dá»±a trÃªn metadata thá»±c tá»« Spotify API*")
        
        with gr.Tab("ðŸ”§ Thiáº¿t láº­p dá»¯ liá»‡u"):
            gr.Markdown("### Thiáº¿t láº­p dá»¯ liá»‡u ban Ä‘áº§u tá»« Spotify API")
            gr.Markdown("*Thu tháº­p metadata thá»±c tá»« Spotify, khÃ´ng sá»­ dá»¥ng synthetic data*")
            
            # Data status check
            with gr.Row():
                with gr.Column():
                    check_data_btn = gr.Button("ðŸ” Kiá»ƒm tra dá»¯ liá»‡u hiá»‡n táº¡i", variant="secondary")
                    data_status_output = gr.Markdown()
                    check_data_btn.click(fn=check_data_status, outputs=data_status_output)
                
                with gr.Column():
                    tracks_per_query = gr.Slider(
                        MIN_TRACKS_PER_QUERY, 
                        MAX_TRACKS_PER_QUERY, 
                        value=DEFAULT_TRACKS_PER_QUERY, 
                        step=TRACKS_QUERY_STEP, 
                        label="Sá»‘ bÃ i hÃ¡t má»—i truy váº¥n"
                    )
                    setup_btn = gr.Button("ðŸš€ Thiáº¿t láº­p dá»¯ liá»‡u", variant="primary")
                    setup_output = gr.Markdown()
                    setup_btn.click(fn=setup_initial_dataset, inputs=[tracks_per_query], outputs=setup_output)

        with gr.Tab("ðŸ¤– Huáº¥n luyá»‡n mÃ´ hÃ¬nh"):
            gr.Markdown("### Huáº¥n luyá»‡n mÃ´ hÃ¬nh Ä‘á» xuáº¥t")
            gr.Markdown("*Huáº¥n luyá»‡n vá»›i real metadata tá»« Spotify (popularity, duration, genre, release_year, v.v.)*")
            train_btn = gr.Button("ðŸ‹ï¸ Huáº¥n luyá»‡n mÃ´ hÃ¬nh", variant="primary")
            train_output = gr.Markdown()
            train_btn.click(fn=train_model, outputs=train_output)

        with gr.Tab("ðŸŽ¯ Äá» xuáº¥t tÆ°Æ¡ng tá»±"):
            gr.Markdown("### Äá» xuáº¥t bÃ i hÃ¡t tÆ°Æ¡ng tá»±")
            gr.Markdown("*Dá»±a trÃªn real Spotify metadata: popularity, genre, artist, release year, duration...*")
            with gr.Row():
                song_input = gr.Textbox(label="ðŸŽµ TÃªn bÃ i hÃ¡t", placeholder="VÃ­ dá»¥: Shape of You")
                artist_input = gr.Textbox(label="ðŸ‘¤ TÃªn nghá»‡ sÄ© (tÃ¹y chá»n)", placeholder="VÃ­ dá»¥: Ed Sheeran")
            n_similar = gr.Slider(5, 20, value=10, step=1, label="ðŸ“Š Sá»‘ lÆ°á»£ng Ä‘á» xuáº¥t")
            rec_btn = gr.Button("ðŸ” Äá» xuáº¥t", variant="primary")
            rec_output = gr.Markdown()
            rec_btn.click(fn=recommend_similar, inputs=[song_input, artist_input, n_similar], outputs=rec_output)
    
    return app

if __name__ == "__main__":
    import argparse
    
    # Khá»Ÿi táº¡o model náº¿u cÃ³
    initialize_model()
    
    parser = argparse.ArgumentParser(description="Há»‡ thá»‘ng Ä‘á» xuáº¥t Ã¢m nháº¡c")
    parser.add_argument("--fetch-large", action="store_true", help="Thu tháº­p táº­p dá»¯ liá»‡u lá»›n (100,000+ bÃ i hÃ¡t)")
    parser.add_argument("--size", type=int, default=LARGE_DATASET_DEFAULT_SIZE, help="KÃ­ch thÆ°á»›c táº­p dá»¯ liá»‡u má»¥c tiÃªu")
    args = parser.parse_args()
    
    if args.fetch_large:
        from utils.data_fetcher import fetch_large_dataset
        fetch_large_dataset(
            target_size=args.size,
            batch_size=LARGE_DATASET_BATCH_SIZE,
            save_interval=LARGE_DATASET_SAVE_INTERVAL
        )
    else:
        demo = create_ui()
        demo.launch()