import os
import logging
import traceback
import pandas as pd
import gradio as gr
from pathlib import Path
from dotenv import load_dotenv

from config.config import (
    RAW_DATA_DIR, PROCESSED_DATA_DIR, MODELS_DIR,
    DEFAULT_TRACKS_PER_QUERY, MAX_TRACKS_PER_QUERY, 
    MIN_TRACKS_PER_QUERY, TRACKS_QUERY_STEP,
    LARGE_DATASET_DEFAULT_SIZE, LARGE_DATASET_BATCH_SIZE, LARGE_DATASET_SAVE_INTERVAL
)
from utils.data_fetcher import fetch_initial_dataset
from utils.data_processor import DataProcessor
from models.enhanced_content_model import EnhancedContentRecommender
from models.weighted_content_model import WeightedContentRecommender
from models.visualization import save_comparison_visualization # <<< TH√äM IMPORT N√ÄY
from datetime import datetime # <<< TH√äM IMPORT N√ÄY

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Load environment variables
load_dotenv(dotenv_path=Path(__file__).parent / '.env')

# Global model variables
model = None
weighted_model = None

# Global state for last recommendation query
last_rec_song = None
last_rec_artist = None
last_rec_n = 10

def initialize_model():
    """Initialize models on app startup"""
    global model, weighted_model
    
    # ‚úÖ Fixed file paths aligned with actual data structure
    model_path = os.path.join(MODELS_DIR, 'enhanced_content_recommender.pkl')
    weighted_model_path = os.path.join(MODELS_DIR, 'weighted_content_recommender.pkl')

    # EnhancedContentRecommender
    if os.path.exists(model_path):
        try:
            model = EnhancedContentRecommender.load(model_path)
            logger.info(f"Loaded EnhancedContentRecommender from {model_path}")
        except Exception as e:
            logger.error(f"Error loading enhanced model: {e}")
            model = None

    # WeightedContentRecommender
    if os.path.exists(weighted_model_path):
        try:
            weighted_model = WeightedContentRecommender.load(weighted_model_path)
            logger.info(f"Loaded WeightedContentRecommender from {weighted_model_path}")
        except Exception as e:
            logger.error(f"Error loading weighted model: {e}")
            weighted_model = None

def check_spotify_credentials():
    """Check if Spotify credentials are configured"""
    from config.config import SPOTIFY_CLIENT_ID, SPOTIFY_CLIENT_SECRET
    return bool(SPOTIFY_CLIENT_ID and SPOTIFY_CLIENT_SECRET)

def setup_initial_dataset(progress=gr.Progress(), tracks_per_query=DEFAULT_TRACKS_PER_QUERY):
    """Setup initial dataset with progress tracking"""
    if not check_spotify_credentials():
        return "‚ö†Ô∏è Missing Spotify credentials. Please setup .env file with SPOTIFY_CLIENT_ID and SPOTIFY_CLIENT_SECRET."
    
    os.makedirs(RAW_DATA_DIR, exist_ok=True)
    progress(0.1, desc="Checking existing data...")
    
    try:
        # ‚úÖ Check actual file paths from data processor
        processed_path = os.path.join(PROCESSED_DATA_DIR, 'processed_tracks.csv')
        
        if os.path.exists(processed_path):
            existing_df = pd.read_csv(processed_path)
            progress(0.3, desc=f"Found {len(existing_df)} existing tracks...")
            
            if len(existing_df) >= 1000:  # Already have sufficient data
                # ‚úÖ TH√äM: Check ISRC coverage
                isrc_coverage = (existing_df.get('isrc', pd.Series()) != '').sum() / len(existing_df)
                
                if isrc_coverage < 0.5:  # Low ISRC coverage
                    progress(0.4, desc="Enhancing data with Spotify API...")
                    processor = DataProcessor()
                    processor.load_data()  # Load existing data
                    processor.enrich_with_spotify_api()  # Enrich with API
                    processor.extract_cultural_features()  # Re-extract with new ISRC
                    processor.save_processed_data()
                    progress(0.7, desc="ISRC data enhanced!")
                
                progress(1.0, desc="Dataset ready!")
                
                # ‚úÖ Check cultural intelligence features
                cultural_features = ['music_culture', 'is_vietnamese', 'is_korean', 'is_japanese']
                available_cultural = [f for f in cultural_features if f in existing_df.columns]
                
                if len(available_cultural) >= 3:
                    return f"‚úÖ Dataset ready with {len(existing_df)} tracks and {len(available_cultural)} cultural intelligence features!"
                else:
                    progress(0.5, desc="Reprocessing for cultural features...")
                    processor = DataProcessor()
                    processor.process_all()
                    progress(1.0, desc="Cultural features updated!")
                    return f"‚úÖ Updated dataset with {len(existing_df)} tracks and enhanced cultural intelligence!"
        
        # Fetch new data
        progress(0.2, desc="Fetching tracks from Spotify...")
        success = fetch_initial_dataset(tracks_per_query=tracks_per_query)
        
        if not success:
            return "‚ùå Failed to fetch tracks from Spotify API."
        
        progress(0.6, desc="Processing data with cultural intelligence...")
        processor = DataProcessor()
        success = processor.process_all()
        
        if not success:
            return "‚ùå Failed to process data."
        
        # ‚úÖ Check final result
        if os.path.exists(processed_path):
            final_df = pd.read_csv(processed_path)
            progress(1.0, desc="Setup complete!")
            
            # ‚úÖ Report on cultural intelligence
            cultural_dist = final_df.get('music_culture', pd.Series()).value_counts().to_dict()
            isrc_coverage = (final_df.get('isrc', pd.Series()) != '').sum() if 'isrc' in final_df.columns else 0
            
            return f"""‚úÖ Dataset setup successful!
            
**üìä Dataset Stats:**
- **Total tracks:** {len(final_df):,}
- **ISRC coverage:** {isrc_coverage}/{len(final_df)} ({isrc_coverage/len(final_df)*100:.1f}%)
- **Cultural distribution:** {cultural_dist}

**üß† Cultural Intelligence Features:**
- ISRC-based culture classification ‚úÖ
- Market penetration analysis ‚úÖ  
- Cross-cultural similarity ‚úÖ
"""
        else:
            return "‚ùå Data processing completed but no output file found."
        
    except Exception as e:
        logger.error(f"Error in setup_initial_dataset: {e}\n{traceback.format_exc()}")
        return f"‚ùå Setup error: {str(e)}"

def train_model():
    """Train or load recommendation models"""
    global model, weighted_model
    
    try:
        # ‚úÖ Fixed file paths
        enhanced_model_path = os.path.join(MODELS_DIR, 'enhanced_content_recommender.pkl')
        weighted_model_path = os.path.join(MODELS_DIR, 'weighted_content_recommender.pkl')
        processed_path = os.path.join(PROCESSED_DATA_DIR, 'processed_tracks.csv')

        # Check data availability
        if not os.path.exists(processed_path):
            return "‚ùå No processed data found. Please setup dataset first."
        
        tracks_df = pd.read_csv(processed_path)
        logger.info(f"Training with {len(tracks_df)} tracks and {len(tracks_df.columns)} features")
        
        # ‚úÖ Validate required features
        required_features = ['id', 'name', 'artist', 'popularity']
        missing_features = [f for f in required_features if f not in tracks_df.columns]
        if missing_features:
            return f"‚ùå Missing required features: {missing_features}. Please reprocess data."
        
        results = []
        
        # Train EnhancedContentRecommender
        if os.path.exists(enhanced_model_path):
            logger.info("Loading existing EnhancedContentRecommender...")
            model = EnhancedContentRecommender.load(enhanced_model_path)
            results.append("‚úÖ EnhancedContentRecommender loaded")
        else:
            logger.info("Training new EnhancedContentRecommender...")
            model = EnhancedContentRecommender()
            success = model.train(tracks_df)
            if success:
                model.save(enhanced_model_path)
                results.append("‚úÖ EnhancedContentRecommender trained and saved")
            else:
                results.append("‚ùå EnhancedContentRecommender training failed")

        # Train WeightedContentRecommender  
        if os.path.exists(weighted_model_path):
            logger.info("Loading existing WeightedContentRecommender...")
            weighted_model = WeightedContentRecommender.load(weighted_model_path)
            results.append("‚úÖ WeightedContentRecommender loaded")
        else:
            logger.info("Training new WeightedContentRecommender...")
            weighted_model = WeightedContentRecommender()
            success = weighted_model.train(tracks_df)
            if success:
                weighted_model.save(weighted_model_path)
                results.append("‚úÖ WeightedContentRecommender trained and saved")
            else:
                results.append("‚ùå WeightedContentRecommender training failed")

        # ‚úÖ Feature quality analysis
        feature_analysis = []
        cultural_features = [col for col in tracks_df.columns if col.startswith('is_') or col == 'music_culture']
        genre_features = [col for col in tracks_df.columns if col.startswith('genre_')]
        
        feature_analysis.append(f"üìä **Cultural features:** {len(cultural_features)}")
        feature_analysis.append(f"üéµ **Genre features:** {len(genre_features)}")
        
        if 'cultural_confidence' in tracks_df.columns:
            avg_confidence = tracks_df['cultural_confidence'].mean()
            feature_analysis.append(f"üß† **Cultural confidence:** {avg_confidence:.3f}")

        return f"""**ü§ñ Model Training Results:**

{chr(10).join(results)}

**üìà Feature Quality:**
{chr(10).join(feature_analysis)}

**üöÄ Ready for recommendations!**"""

    except Exception as e:
        logger.error(f"Error training models: {e}\n{traceback.format_exc()}")
        return f"‚ùå Training error: {str(e)}"

def recommend_similar(song_name, artist_name="", n=10):
    """Generate recommendations with both models and update last query state."""
    global model, weighted_model, last_rec_song, last_rec_artist, last_rec_n
    
    # Update last query state
    last_rec_song = song_name
    last_rec_artist = artist_name
    last_rec_n = n
    logger.info(f"Updated last recommendation query: Song='{song_name}', Artist='{artist_name}', N={n}")

    if model is None or not model.is_trained:
        return "‚ö†Ô∏è EnhancedContentRecommender not trained. Please train models first."
    if weighted_model is None or not weighted_model.is_trained:
        return "‚ö†Ô∏è WeightedContentRecommender not trained. Please train models first."
    
    try:
        # ‚úÖ Load data for context
        processed_path = os.path.join(PROCESSED_DATA_DIR, 'processed_tracks.csv')
        if os.path.exists(processed_path):
            tracks_df = pd.read_csv(processed_path)
            
            # Find seed track for context
            mask = tracks_df['name'].str.lower().str.strip() == song_name.lower().strip()
            if artist_name:
                mask = mask & (tracks_df['artist'].str.lower().str.strip() == artist_name.lower().strip())
            
            found_tracks = tracks_df[mask]
            
            if found_tracks.empty:
                # Try partial matching
                mask = tracks_df['name'].str.lower().str.contains(song_name.lower(), na=False)
                if artist_name:
                    mask = mask & tracks_df['artist'].str.lower().str.contains(artist_name.lower(), na=False)
                found_tracks = tracks_df[mask]
            
            # ‚úÖ Show seed track info with cultural context
            if not found_tracks.empty:
                seed_track = found_tracks.iloc[0]
                seed_culture = seed_track.get('music_culture', 'other')
                seed_confidence = seed_track.get('cultural_confidence', 0)
                
                seed_info = f"""**üéµ Seed Track:** {seed_track['name']} - {seed_track['artist']}
**üåç Culture:** {seed_culture} | **üìä Popularity:** {seed_track.get('popularity', 'N/A')}
**üìÖ Year:** {seed_track.get('release_year', 'N/A')} | **üß† Cultural Confidence:** {seed_confidence:.3f}

---
"""
            else:
                seed_info = f"**‚ö†Ô∏è Track '{song_name}' not found in database. Showing similar recommendations...**\n\n---\n"
        else:
            seed_info = "**üéµ Generating recommendations...**\n\n---\n"

        # ‚úÖ Generate recommendations with error handling
        logger.info(f"Generating recommendations for '{song_name}' by '{artist_name}'")
        
        results = []
        
        # EnhancedContentRecommender
        try:
            enhanced_recs = model.recommend(track_name=song_name, artist=artist_name, n_recommendations=n)
            if not enhanced_recs.empty:
                results.append("## üîç EnhancedContentRecommender:")
                
                display_cols = ['name', 'artist', 'enhanced_score']
                if 'music_culture' in enhanced_recs.columns:
                    display_cols.insert(-1, 'music_culture')
                if 'popularity' in enhanced_recs.columns:
                    display_cols.insert(-1, 'popularity')
                
                available_cols = [col for col in display_cols if col in enhanced_recs.columns]
                results.append(enhanced_recs[available_cols].round(3).to_markdown(index=False))
                
                # ‚úÖ Cultural analytics
                if 'music_culture' in enhanced_recs.columns:
                    culture_dist = enhanced_recs['music_culture'].value_counts()
                    results.append(f"**üåç Cultural diversity:** {dict(culture_dist)}")
                
                avg_score = enhanced_recs['enhanced_score'].mean() if 'enhanced_score' in enhanced_recs.columns else 0
                results.append(f"**üìà Avg enhanced score:** {avg_score:.3f}")
            else:
                results.append("## üîç EnhancedContentRecommender:\n‚ùå No recommendations generated")
        except Exception as e:
            logger.error(f"EnhancedContentRecommender failed: {e}")
            results.append("## üîç EnhancedContentRecommender:\n‚ùå Model error")

        results.append("\n---\n")

        # WeightedContentRecommender
        try:
            weighted_recs = weighted_model.recommend(track_name=song_name, artist=artist_name, n_recommendations=n)
            if not weighted_recs.empty:
                results.append("## üéØ WeightedContentRecommender (ISRC Cultural + Genre Weights):")
                
                display_cols = ['name', 'artist', 'final_score']
                if 'music_culture' in weighted_recs.columns:
                    display_cols.insert(-1, 'music_culture')
                if 'popularity' in weighted_recs.columns:
                    display_cols.insert(-1, 'popularity')
                
                available_cols = [col for col in display_cols if col in weighted_recs.columns]
                results.append(weighted_recs[available_cols].round(3).to_markdown(index=False))
                
                # ‚úÖ Cultural analytics
                if 'music_culture' in weighted_recs.columns:
                    culture_dist = weighted_recs['music_culture'].value_counts()
                    results.append(f"**üåç Cultural diversity:** {dict(culture_dist)}")
                
                avg_score = weighted_recs['final_score'].mean() if 'final_score' in weighted_recs.columns else 0
                results.append(f"**üìà Avg weighted score:** {avg_score:.3f}")
            else:
                results.append("## üéØ WeightedContentRecommender:\n‚ùå No recommendations generated")
        except Exception as e:
            logger.error(f"WeightedContentRecommender failed: {e}")
            results.append("## üéØ WeightedContentRecommender:\n‚ùå Model error")

        return seed_info + "\n".join(results)
        
    except Exception as e:
        logger.error(f"Recommendation error: {e}\n{traceback.format_exc()}")
        return f"‚ùå System error: {str(e)}"

def check_data_status():
    """Check data completeness and quality"""
    try:
        # ‚úÖ Simple data status check
        raw_tracks = os.path.join(RAW_DATA_DIR, 'tracks.csv')
        processed_tracks = os.path.join(PROCESSED_DATA_DIR, 'processed_tracks.csv')
        
        status_lines = []
        score = 0
        max_score = 5
        
        # Check raw data
        if os.path.exists(raw_tracks):
            raw_df = pd.read_csv(raw_tracks)
            status_lines.append(f"**Raw data:** {len(raw_df):,} tracks")
            score += 1
        else:
            status_lines.append("**Raw data:** Not found")
        
        # Check processed data
        if os.path.exists(processed_tracks):
            processed_df = pd.read_csv(processed_tracks)
            status_lines.append(f"‚úÖ **Processed data:** {len(processed_df):,} tracks")
            score += 1
            
            # Check cultural features
            cultural_features = [col for col in processed_df.columns if col.startswith('is_') or col == 'music_culture']
            if len(cultural_features) >= 3:
                status_lines.append(f"‚úÖ **Cultural intelligence:** {len(cultural_features)} features")
                score += 1
            else:
                status_lines.append("‚ö†Ô∏è **Cultural intelligence:** Limited features")
            
            # Check ISRC coverage
            if 'isrc' in processed_df.columns:
                isrc_coverage = (processed_df['isrc'] != '').sum() / len(processed_df)
                if isrc_coverage > 0.5:
                    status_lines.append(f"‚úÖ **ISRC coverage:** {isrc_coverage*100:.1f}%")
                    score += 1
                else:
                    status_lines.append(f"‚ö†Ô∏è **ISRC coverage:** {isrc_coverage*100:.1f}% (low)")
            
            # Check genre features
            genre_features = [col for col in processed_df.columns if col.startswith('genre_')]
            if len(genre_features) >= 20:  # Adjusted threshold from 3 to 20
                status_lines.append(f"‚úÖ **Genre features:** {len(genre_features)} types")
                score += 1
                
                # Add top genres information
                if len(genre_features) > 0:
                    # Get top 5 genres by count
                    genre_counts = {}
                    for genre in genre_features:
                        genre_counts[genre[6:]] = processed_df[genre].sum()  # Remove 'genre_' prefix
                    
                    top_genres = sorted(genre_counts.items(), key=lambda x: x[1], reverse=True)[:5]
                    top_genres_str = ", ".join([f"{genre} ({count})" for genre, count in top_genres])
                    status_lines.append(f"üìä **Top genres:** {top_genres_str}")
            else:
                status_lines.append(f"‚ö†Ô∏è **Genre features:** Limited ({len(genre_features)} types)")
        else:
            status_lines.append("‚ùå **Processed data:** Not found")
        
        # Check models
        enhanced_model_path = os.path.join(MODELS_DIR, 'enhanced_content_recommender.pkl')
        weighted_model_path = os.path.join(MODELS_DIR, 'weighted_content_recommender.pkl')
        
        if os.path.exists(enhanced_model_path) and os.path.exists(weighted_model_path):
            status_lines.append("‚úÖ **Models:** Both models available")
        elif os.path.exists(enhanced_model_path) or os.path.exists(weighted_model_path):
            status_lines.append("‚ö†Ô∏è **Models:** Partial availability")
        else:
            status_lines.append("‚ùå **Models:** Not trained")

        # Overall status
        if score >= 4:
            overall_status = "üöÄ **EXCELLENT** - Production ready!"
        elif score >= 3:
            overall_status = "‚úÖ **GOOD** - Ready for recommendations"
        elif score >= 2:
            overall_status = "‚ö†Ô∏è **FAIR** - Basic functionality"
        else:
            overall_status = "‚ùå **POOR** - Need more data"

        return f"""# üìä Data Status Report

{overall_status}

**Readiness Score:** {score}/{max_score} ({score/max_score*100:.0f}%)

## Detailed Status:
{chr(10).join(status_lines)}

## Next Steps:
- Score < 3: Run data setup
- Score < 4: Train models
- Score ‚â• 4: Ready for recommendations!
"""
        
    except Exception as e:
        logger.error(f"Error checking data status: {e}")
        return f"‚ùå **Error checking data status:** {str(e)}"

def generate_and_show_comparison_chart(song_name, artist_name, n_recs, request: gr.Request = None):
    """
    Generates and returns the path to the model comparison chart.
    If song_name is None, it tries to use the last recommended song.
    """
    global model, weighted_model, last_rec_song, last_rec_artist, last_rec_n

    # Use last recommended song if no specific song is provided for the chart
    # This is useful when the tab is selected.
    if song_name is None and artist_name is None and n_recs is None:
        if last_rec_song:
            song_name = last_rec_song
            artist_name = last_rec_artist
            n_recs = last_rec_n
            logger.info(f"Using last recommendation for chart: Song='{song_name}', Artist='{artist_name}', N={n_recs}")
        else:
            return None, "‚ÑπÔ∏è Perform a recommendation in the 'Recommendations' tab first, or enter a song here to generate a comparison chart."

    if not model or not model.is_trained:
        return None, "‚ö†Ô∏è EnhancedContentRecommender not trained. Please train models first."
    if not weighted_model or not weighted_model.is_trained:
        return None, "‚ö†Ô∏è WeightedContentRecommender not trained. Please train models first."

    if not song_name: # song_name could still be None if last_rec_song was also None
        return None, "‚ö†Ô∏è Please enter a Song Name or perform a recommendation first."

    try:
        # Define an output path for the chart in a subdirectory
        charts_dir = os.path.join(Path(__file__).parent, 'outputs', 'charts')
        os.makedirs(charts_dir, exist_ok=True)
        
        # Create a unique filename to avoid browser caching issues with the same name
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        chart_filename = f"model_comparison_{song_name.replace(' ', '_')}_{timestamp}.png"
        output_chart_path = os.path.join(charts_dir, chart_filename)

        logger.info(f"Generating comparison chart for '{song_name}' by '{artist_name or 'N/A'}' to {output_chart_path}")

        saved_chart_path = save_comparison_visualization(
            enhanced_model=model,
            weighted_model=weighted_model,
            track_name=song_name,
            artist=artist_name if artist_name else None,
            n_recommendations=int(n_recs),
            output_path=output_chart_path
        )

        if saved_chart_path:
            logger.info(f"Comparison chart saved to: {saved_chart_path}")
            return saved_chart_path, f"‚úÖ Comparison chart generated for '{song_name}'."
        else:
            # save_comparison_visualization logs errors internally if fig is None or save fails
            # compare_recommendation_models also returns a figure with an error message if recs are empty or models not trained
            # So, if saved_chart_path is None, it means an error occurred during saving or figure generation.
            # The visualization module should have logged the specific error.
            # We can check if the output_chart_path (which might contain an error image) exists.
            if os.path.exists(output_chart_path):
                 return output_chart_path, "‚ö†Ô∏è Chart generated, but there might be issues (e.g., no recommendations found). Check chart content."
            return None, "‚ùå Failed to generate comparison chart. Check application logs for more details."

    except Exception as e:
        logger.error(f"Error in generate_and_show_comparison_chart: {e}\n{traceback.format_exc()}")
        return None, f"‚ùå System error while generating chart: {str(e)}"

def create_ui():
    """Create Gradio interface"""
    # State variables to store the last recommendation query
    # These are not directly used as inputs/outputs in gr.Blocks context for this specific auto-refresh,
    # we'll use global Python variables for simplicity here, updated by recommend_similar.
    # For more complex state management across sessions or users, gr.State with session state would be better.

    with gr.Blocks(title="Music Recommender - ISRC Cultural Intelligence", theme=gr.themes.Soft()) as app:
        gr.Markdown("# üéµ Music Recommender - ISRC Cultural Intelligence")
        gr.Markdown("*Advanced recommendation system with ISRC-based cultural intelligence and Spotify metadata*")
        
        with gr.Tab("üîß Data Setup"):
            gr.Markdown("### Setup Dataset from Spotify API")
            gr.Markdown("*Collect real metadata with ISRC cultural intelligence*")
            
            with gr.Row():
                with gr.Column():
                    check_data_btn = gr.Button("üîç Check Current Data", variant="secondary")
                    data_status_output = gr.Markdown()
                    check_data_btn.click(fn=check_data_status, outputs=data_status_output)
                
                with gr.Column():
                    tracks_per_query = gr.Slider(
                        MIN_TRACKS_PER_QUERY, 
                        MAX_TRACKS_PER_QUERY, 
                        value=DEFAULT_TRACKS_PER_QUERY, 
                        step=TRACKS_QUERY_STEP, 
                        label="Tracks per Query"
                    )
                    setup_btn = gr.Button("üöÄ Setup Dataset", variant="primary")
                    setup_output = gr.Markdown()
                    setup_btn.click(fn=setup_initial_dataset, inputs=[tracks_per_query], outputs=setup_output)

        with gr.Tab("ü§ñ Model Training"):
            gr.Markdown("### Train Recommendation Models")
            gr.Markdown("*Train with ISRC cultural intelligence and real Spotify features*")
            train_btn = gr.Button("üèãÔ∏è Train Models", variant="primary")
            train_output = gr.Markdown()
            train_btn.click(fn=train_model, outputs=train_output)

        with gr.Tab("üéØ Recommendations"):
            gr.Markdown("### Smart Music Recommendations")
            gr.Markdown("*Powered by ISRC cultural intelligence and weighted content features*")
            
            with gr.Row():
                song_input = gr.Textbox(label="üéµ Song Name", placeholder="e.g., Dynamite")
                artist_input = gr.Textbox(label="üë§ Artist Name (optional)", placeholder="e.g., BTS")
            
            n_similar = gr.Slider(5, 20, value=10, step=1, label="üìä Number of Recommendations")
            rec_btn = gr.Button("üîç Get Recommendations", variant="primary")
            rec_output = gr.Markdown()
            # The recommend_similar function will now update global state
            rec_btn.click(fn=recommend_similar, inputs=[song_input, artist_input, n_similar], outputs=rec_output)


        with gr.Tab("üìä Model Comparison") as comparison_tab: 
            gr.Markdown("### üìà Compare Recommendation Model Performance")
            gr.Markdown("*Visualize differences in recommendations, diversity, and performance. The chart automatically updates based on the last song recommended in the 'Recommendations' tab.*")
            
            # Outputs for the chart and status (will be updated when tab is selected)
            auto_comparison_status_output = gr.Markdown()
            auto_comparison_chart_output = gr.Image(label="Last Recommendation Comparison Chart", type="filepath", interactive=False)

            # Action to trigger when the "Model Comparison" tab is selected
            def refresh_comparison_on_tab_select():
                logger.info("Model Comparison tab selected. Attempting to generate chart for last recommendation.")
                # Call with None inputs to use the global state
                return generate_and_show_comparison_chart(None, None, None)

            comparison_tab.select(
                fn=refresh_comparison_on_tab_select,
                inputs=None, # No direct inputs from UI for this auto-refresh
                outputs=[auto_comparison_chart_output, auto_comparison_status_output]
            )
            
    return app

if __name__ == "__main__":
    # Initialize models if available
    initialize_model()
    
    # Create and launch UI
    demo = create_ui()
    demo.launch(share=False, server_name="0.0.0.0", server_port=7860)
