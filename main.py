import os
import logging
import traceback
from pathlib import Path
from dotenv import load_dotenv
import gradio as gr
import pandas as pd
import numpy as np
import pickle

from config.config import (
    RAW_DATA_DIR, PROCESSED_DATA_DIR, MODELS_DIR,
    DEFAULT_TRACKS_PER_QUERY, MAX_TRACKS_PER_QUERY, 
    MIN_TRACKS_PER_QUERY, TRACKS_QUERY_STEP,
    LARGE_DATASET_DEFAULT_SIZE, LARGE_DATASET_BATCH_SIZE, LARGE_DATASET_SAVE_INTERVAL
)
from utils.data_fetcher import fetch_initial_dataset
from utils.data_processor import DataProcessor
from models.hybrid_model import MetadataRecommender
from models.weighted_content_model import WeightedContentRecommender

# Thi·∫øt l·∫≠p logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Load bi·∫øn m√¥i tr∆∞·ªùng
load_dotenv(dotenv_path=Path(__file__).parent / '.env')

# Bi·∫øn to√†n c·ª•c cho model
model = None
weighted_model = None

def initialize_model():
    """Kh·ªüi t·∫°o model khi kh·ªüi ƒë·ªông ·ª©ng d·ª•ng"""
    global model, weighted_model
    model_path = os.path.join(MODELS_DIR, 'metadata_recommender.pkl')
    weighted_model_path = os.path.join(MODELS_DIR, 'weighted_content_recommender.pkl')

    # MetadataRecommender
    if os.path.exists(model_path):
        try:
            model = MetadataRecommender.load(model_path)
            logging.info(f"ƒê√£ n·∫°p model t·ª´ {model_path}")
            logging.info(f"Model ƒë∆∞·ª£c hu·∫•n luy·ªán v√†o: {model.train_time}")
        except Exception as e:
            logging.error(f"L·ªói khi n·∫°p model: {e}")
            model = None

    # WeightedContentRecommender
    if os.path.exists(weighted_model_path):
        try:
            weighted_model = WeightedContentRecommender.load(weighted_model_path)
            logging.info(f"ƒê√£ n·∫°p weighted model t·ª´ {weighted_model_path}")
        except Exception as e:
            logging.error(f"L·ªói khi n·∫°p weighted model: {e}")
            weighted_model = None

def check_spotify_credentials():
    from config.config import SPOTIFY_CLIENT_ID, SPOTIFY_CLIENT_SECRET
    return bool(SPOTIFY_CLIENT_ID and SPOTIFY_CLIENT_SECRET)

def setup_initial_dataset(progress=gr.Progress(), tracks_per_query=DEFAULT_TRACKS_PER_QUERY):
    """Thi·∫øt l·∫≠p b·ªô d·ªØ li·ªáu ban ƒë·∫ßu v·ªõi progress bar"""
    if not check_spotify_credentials():
        return "‚ö†Ô∏è Thi·∫øu th√¥ng tin x√°c th·ª±c Spotify. Vui l√≤ng thi·∫øt l·∫≠p file .env."
    os.makedirs(RAW_DATA_DIR, exist_ok=True)
    progress(0.1, desc="ƒêang thu th·∫≠p d·ªØ li·ªáu t·ª´ Spotify...")
    try:
        tracks_df = fetch_initial_dataset(tracks_per_query=tracks_per_query)
        if tracks_df is None or tracks_df.empty:
            return "‚ùå Kh√¥ng th·ªÉ l·∫•y d·ªØ li·ªáu b√†i h√°t t·ª´ Spotify."
        progress(0.6, desc="ƒêang x·ª≠ l√Ω d·ªØ li·ªáu...")
        processor = DataProcessor()
        processor.process_all()
        progress(1.0, desc="Ho√†n t·∫•t!")
        return f"‚úÖ ƒê√£ thi·∫øt l·∫≠p d·ªØ li·ªáu v·ªõi {len(tracks_df)} b√†i h√°t."
    except Exception as e:
        logger.error(f"L·ªói thi·∫øt l·∫≠p d·ªØ li·ªáu: {e}\n{traceback.format_exc()}")
        return f"‚ùå L·ªói thi·∫øt l·∫≠p d·ªØ li·ªáu: {e}"

def train_model():
    """Hu·∫•n luy·ªán ho·∫∑c n·∫°p l·∫°i m√¥ h√¨nh ƒë·ªÅ xu·∫•t d·ª±a tr√™n metadata"""
    global model, weighted_model
    try:
        # ƒê∆∞·ªùng d·∫´n ƒë·ªÉ l∆∞u/n·∫°p m√¥ h√¨nh
        model_path = os.path.join(MODELS_DIR, 'metadata_recommender.pkl')
        weighted_model_path = os.path.join(MODELS_DIR, 'weighted_content_recommender.pkl')

        # Ki·ªÉm tra xem m√¥ h√¨nh ƒë√£ t·ªìn t·∫°i ch∆∞a
        if os.path.exists(model_path):
            logging.info("T√¨m th·∫•y m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán, ƒëang n·∫°p...")
            model = MetadataRecommender.load(model_path)
            logging.info(f"ƒê√£ n·∫°p m√¥ h√¨nh th√†nh c√¥ng (ƒë∆∞·ª£c hu·∫•n luy·ªán v√†o: {model.train_time})")
        else:
            logging.info("Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh ƒë√£ l∆∞u, ƒëang hu·∫•n luy·ªán m·ªõi...")
            processed_path = os.path.join(PROCESSED_DATA_DIR, 'track_features.csv')
            if not os.path.exists(processed_path):
                processor = DataProcessor()
                processor.process_all()
            tracks_df = pd.read_csv(processed_path)
            model = MetadataRecommender()
            model.train(tracks_df)
            model.save(model_path)
            logging.info(f"ƒê√£ hu·∫•n luy·ªán v√† l∆∞u m√¥ h√¨nh MetadataRecommender th√†nh c√¥ng!")

        # WeightedContentRecommender
        if os.path.exists(weighted_model_path):
            logging.info("T√¨m th·∫•y weighted model ƒë√£ hu·∫•n luy·ªán, ƒëang n·∫°p...")
            weighted_model = WeightedContentRecommender.load(weighted_model_path)
            logging.info("ƒê√£ n·∫°p weighted model th√†nh c√¥ng!")
        else:
            logging.info("Kh√¥ng t√¨m th·∫•y weighted model ƒë√£ l∆∞u, ƒëang hu·∫•n luy·ªán m·ªõi...")
            processed_path = os.path.join(PROCESSED_DATA_DIR, 'track_features.csv')
            if not os.path.exists(processed_path):
                processor = DataProcessor()
                processor.process_all()
            tracks_df = pd.read_csv(processed_path)
            weighted_model = WeightedContentRecommender()
            weighted_model.train(tracks_df)
            weighted_model.save(weighted_model_path)
            logging.info("ƒê√£ hu·∫•n luy·ªán v√† l∆∞u weighted model th√†nh c√¥ng!")

        return "ƒê√£ hu·∫•n luy·ªán c·∫£ hai m√¥ h√¨nh th√†nh c√¥ng!"
    except Exception as e:
        logging.error(f"L·ªói khi hu·∫•n luy·ªán m√¥ h√¨nh: {str(e)}")
        return f"L·ªói khi hu·∫•n luy·ªán m√¥ h√¨nh: {str(e)}"

def recommend_similar(song_name, artist_name="", n=10):
    """ƒê·ªÅ xu·∫•t b√†i h√°t t∆∞∆°ng t·ª± d·ª±a tr√™n real metadata"""
    global model, weighted_model
    if model is None or not model.is_trained:
        return "‚ö†Ô∏è M√¥ h√¨nh Metadata ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán. Vui l√≤ng hu·∫•n luy·ªán m√¥ h√¨nh tr∆∞·ªõc."
    if weighted_model is None or not weighted_model.is_trained:
        return "‚ö†Ô∏è M√¥ h√¨nh Weighted ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán. Vui l√≤ng hu·∫•n luy·ªán m√¥ h√¨nh tr∆∞·ªõc."
    
    try:
        # Ki·ªÉm tra xem b√†i h√°t c√≥ t·ªìn t·∫°i trong d·ªØ li·ªáu kh√¥ng
        processed_path = os.path.join(PROCESSED_DATA_DIR, 'track_features.csv')
        if os.path.exists(processed_path):
            tracks_df = pd.read_csv(processed_path)
            
            # T√¨m b√†i h√°t g·ªëc trong d·ªØ li·ªáu
            mask = tracks_df['name'].str.lower().str.strip() == song_name.lower().strip()
            if artist_name:
                mask = mask & (tracks_df['artist'].str.lower().str.strip() == artist_name.lower().strip())
            
            found_tracks = tracks_df[mask]
            
            if found_tracks.empty:
                available_tracks_sample = tracks_df[['name', 'artist']].head(5)
                return f"""‚ùå Kh√¥ng t√¨m th·∫•y b√†i h√°t **{song_name}** (ngh·ªá sƒ©: {artist_name}) trong d·ªØ li·ªáu.

**M·ªôt s·ªë b√†i h√°t c√≥ s·∫µn:**
{available_tracks_sample.to_markdown(index=False)}

Vui l√≤ng ki·ªÉm tra l·∫°i t√™n b√†i h√°t v√† ngh·ªá sƒ©!"""
            
            # Hi·ªÉn th·ªã th√¥ng tin b√†i h√°t g·ªëc
            original_info = found_tracks.iloc[0]
            seed_info = f"""**üéµ B√†i h√°t g·ªëc:** {original_info['name']} - {original_info['artist']}
**Popularity:** {original_info.get('popularity', 'N/A')} | **NƒÉm ph√°t h√†nh:** {original_info.get('release_year', 'N/A')}

---
"""
        else:
            seed_info = ""
        
        # Th·ª±c hi·ªán ƒë·ªÅ xu·∫•t
        logger.info(f"Generating recommendations for '{song_name}' by {artist_name} using real metadata")
        rec1 = model.recommend(track_name=song_name, artist=artist_name, n_recommendations=n)
        rec2 = weighted_model.recommend(track_name=song_name, artist=artist_name, n_recommendations=n)
        
        # Hi·ªÉn th·ªã k·∫øt qu·∫£
        result = seed_info
        
        result += "### üìä ƒê·ªÅ xu·∫•t theo MetadataRecommender (Real Spotify Metadata):\n"
        if isinstance(rec1, str):
            result += rec1 + "\n"
        elif not rec1.empty:
            # Format cho ƒë·∫πp h∆°n
            display_cols = ['name', 'artist', 'content_score', 'popularity', 'release_year']
            available_cols = [col for col in display_cols if col in rec1.columns]
            result += rec1[available_cols].to_markdown(index=False) + "\n"
        else:
            result += "Kh√¥ng c√≥ ƒë·ªÅ xu·∫•t.\n"
        
        result += "\n---\n### ‚öñÔ∏è ƒê·ªÅ xu·∫•t theo WeightedContentRecommender (Weighted Real Features):\n"
        if isinstance(rec2, str):
            result += rec2
        elif not rec2.empty:
            available_cols = [col for col in display_cols if col in rec2.columns]
            result += rec2[available_cols].to_markdown(index=False)
        else:
            result += "Kh√¥ng c√≥ ƒë·ªÅ xu·∫•t."
        
        return result
        
    except Exception as e:
        logger.error(f"L·ªói khi ƒë·ªÅ xu·∫•t: {e}\n{traceback.format_exc()}")
        return f"‚ùå L·ªói khi ƒë·ªÅ xu·∫•t: {str(e)}"

def discover_by_genre(genre, n=10):
    global model
    if model is None or not model.is_trained:
        return "‚ö†Ô∏è Vui l√≤ng hu·∫•n luy·ªán m√¥ h√¨nh tr∆∞·ªõc."
    try:
        recs = model.discover_by_genre(genre, n)
        if recs is None or recs.empty:
            return f"Kh√¥ng t√¨m th·∫•y b√†i h√°t thu·ªôc th·ªÉ lo·∫°i {genre}."
        result = f"## Top {n} b√†i h√°t th·ªÉ lo·∫°i {genre}\n"
        for i, row in enumerate(recs.itertuples(), 1):
            result += f"{i}. **{row.name}** - {row.artist}\n"
        return result
    except Exception as e:
        logger.error(f"L·ªói kh√°m ph√° th·ªÉ lo·∫°i: {e}\n{traceback.format_exc()}")
        return f"‚ùå L·ªói kh√°m ph√° th·ªÉ lo·∫°i: {e}"

def create_ui():
    with gr.Blocks(title="Music Recommender (Real Spotify Metadata)", theme=gr.themes.Soft()) as app:
        gr.Markdown("# üéµ Music Recommender - Real Spotify Data Only")
        gr.Markdown("*H·ªá th·ªëng ƒë·ªÅ xu·∫•t √¢m nh·∫°c d·ª±a tr√™n metadata th·ª±c t·ª´ Spotify API*")
        
        with gr.Tab("üîß Thi·∫øt l·∫≠p d·ªØ li·ªáu"):
            gr.Markdown("### Thi·∫øt l·∫≠p d·ªØ li·ªáu ban ƒë·∫ßu t·ª´ Spotify API")
            gr.Markdown("*Thu th·∫≠p metadata th·ª±c t·ª´ Spotify, kh√¥ng s·ª≠ d·ª•ng synthetic data*")
            tracks_per_query = gr.Slider(
                MIN_TRACKS_PER_QUERY, 
                MAX_TRACKS_PER_QUERY, 
                value=DEFAULT_TRACKS_PER_QUERY, 
                step=TRACKS_QUERY_STEP, 
                label="S·ªë b√†i h√°t m·ªói truy v·∫•n"
            )
            setup_btn = gr.Button("üöÄ Thi·∫øt l·∫≠p d·ªØ li·ªáu", variant="primary")
            setup_output = gr.Markdown()
            setup_btn.click(fn=setup_initial_dataset, inputs=[tracks_per_query], outputs=setup_output)

        with gr.Tab("ü§ñ Hu·∫•n luy·ªán m√¥ h√¨nh"):
            gr.Markdown("### Hu·∫•n luy·ªán m√¥ h√¨nh ƒë·ªÅ xu·∫•t")
            gr.Markdown("*Hu·∫•n luy·ªán v·ªõi real metadata t·ª´ Spotify (popularity, duration, genre, release_year, v.v.)*")
            train_btn = gr.Button("üèãÔ∏è Hu·∫•n luy·ªán m√¥ h√¨nh", variant="primary")
            train_output = gr.Markdown()
            train_btn.click(fn=train_model, outputs=train_output)

        with gr.Tab("üéØ ƒê·ªÅ xu·∫•t t∆∞∆°ng t·ª±"):
            gr.Markdown("### ƒê·ªÅ xu·∫•t b√†i h√°t t∆∞∆°ng t·ª±")
            gr.Markdown("*D·ª±a tr√™n real Spotify metadata: popularity, genre, artist, release year, duration...*")
            with gr.Row():
                song_input = gr.Textbox(label="üéµ T√™n b√†i h√°t", placeholder="V√≠ d·ª•: Shape of You")
                artist_input = gr.Textbox(label="üë§ T√™n ngh·ªá sƒ© (t√πy ch·ªçn)", placeholder="V√≠ d·ª•: Ed Sheeran")
            n_similar = gr.Slider(5, 20, value=10, step=1, label="üìä S·ªë l∆∞·ª£ng ƒë·ªÅ xu·∫•t")
            rec_btn = gr.Button("üîç ƒê·ªÅ xu·∫•t", variant="primary")
            rec_output = gr.Markdown()
            rec_btn.click(fn=recommend_similar, inputs=[song_input, artist_input, n_similar], outputs=rec_output)
    
    return app

if __name__ == "__main__":
    import argparse
    
    # Kh·ªüi t·∫°o model n·∫øu c√≥
    initialize_model()
    
    parser = argparse.ArgumentParser(description="H·ªá th·ªëng ƒë·ªÅ xu·∫•t √¢m nh·∫°c")
    parser.add_argument("--fetch-large", action="store_true", help="Thu th·∫≠p t·∫≠p d·ªØ li·ªáu l·ªõn (100,000+ b√†i h√°t)")
    parser.add_argument("--size", type=int, default=LARGE_DATASET_DEFAULT_SIZE, help="K√≠ch th∆∞·ªõc t·∫≠p d·ªØ li·ªáu m·ª•c ti√™u")
    args = parser.parse_args()
    
    if args.fetch_large:
        from utils.data_fetcher import fetch_large_dataset
        fetch_large_dataset(
            target_size=args.size,
            batch_size=LARGE_DATASET_BATCH_SIZE,
            save_interval=LARGE_DATASET_SAVE_INTERVAL
        )
    else:
        demo = create_ui()
        demo.launch()